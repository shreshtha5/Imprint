{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TextDocPreprocessor2\n",
    "doc_preprocessor = TextDocPreprocessor2('data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========                                ] 20%data2/doc7\n",
      "[========                                ] 20%data2/doc40\n",
      "[================                        ] 40%data2/doc116\n",
      "[========================                ] 60%data2/doc137\n",
      "[================================        ] 80%data2/doc19\n",
      "[========================================] 100%data2/doc20\n",
      "[================================================] 120%data2/doc71\n",
      "data2/doc14\n",
      "data2/doc95\n",
      "data2/doc59\n",
      "data2/doc58\n",
      "data2/doc3\n",
      "data2/doc141\n",
      "data2/doc56\n",
      "data2/doc104\n",
      "data2/doc13\n",
      "data2/doc72\n",
      "data2/doc129\n",
      "data2/doc9\n",
      "data2/doc78\n",
      "data2/doc106\n",
      "data2/doc93\n",
      "data2/doc131\n",
      "data2/doc51\n",
      "data2/doc8\n",
      "data2/doc94\n",
      "data2/doc47\n",
      "data2/doc23\n",
      "data2/doc144\n",
      "data2/doc67\n",
      "data2/doc74\n",
      "data2/doc44\n",
      "data2/doc70\n",
      "data2/doc64\n",
      "data2/doc133\n",
      "data2/doc124\n",
      "data2/doc118\n",
      "data2/doc111\n",
      "data2/doc100\n",
      "data2/doc82\n",
      "data2/doc114\n",
      "data2/doc123\n",
      "data2/doc69\n",
      "data2/doc4\n",
      "data2/doc103\n",
      "data2/doc12\n",
      "data2/doc80\n",
      "data2/doc149\n",
      "data2/doc21\n",
      "data2/doc61\n",
      "data2/doc79\n",
      "data2/doc24\n",
      "data2/doc34\n",
      "data2/doc36\n",
      "data2/doc85\n",
      "data2/doc54\n",
      "data2/doc128\n",
      "data2/doc132\n",
      "data2/doc105\n",
      "data2/doc53\n",
      "data2/doc92\n",
      "data2/doc49\n",
      "data2/doc112\n",
      "data2/doc102\n",
      "data2/doc109\n",
      "data2/doc28\n",
      "data2/doc142\n",
      "data2/doc76\n",
      "data2/doc87\n",
      "data2/doc77\n",
      "data2/doc17\n",
      "data2/doc2\n",
      "data2/doc88\n",
      "data2/doc33\n",
      "data2/doc25\n",
      "data2/doc32\n",
      "data2/doc90\n",
      "data2/doc110\n",
      "data2/doc5\n",
      "data2/doc99\n",
      "data2/doc31\n",
      "data2/doc122\n",
      "data2/doc29\n",
      "data2/doc101\n",
      "data2/doc63\n",
      "data2/doc48\n",
      "data2/doc10\n",
      "data2/doc148\n",
      "data2/doc138\n",
      "data2/doc120\n",
      "data2/doc35\n",
      "data2/doc75\n",
      "data2/doc108\n",
      "data2/doc62\n",
      "data2/doc11\n",
      "data2/doc16\n",
      "data2/doc73\n",
      "data2/doc15\n",
      "data2/doc134\n",
      "data2/doc52\n",
      "data2/doc97\n",
      "data2/doc89\n",
      "data2/doc26\n",
      "data2/doc60\n",
      "data2/doc140\n",
      "data2/doc119\n",
      "data2/doc6\n",
      "data2/doc42\n",
      "data2/doc38\n",
      "data2/doc50\n",
      "data2/doc30\n",
      "data2/doc81\n",
      "data2/doc22\n",
      "data2/doc1\n",
      "data2/doc39\n",
      "data2/doc127\n",
      "data2/doc151\n",
      "data2/doc65\n",
      "data2/doc68\n",
      "data2/doc126\n",
      "data2/doc139\n",
      "data2/doc66\n",
      "data2/doc55\n",
      "data2/doc147\n",
      "data2/doc96\n",
      "data2/doc86\n",
      "data2/doc37\n",
      "data2/doc41\n",
      "data2/doc27\n",
      "data2/doc107\n",
      "data2/doc125\n",
      "data2/doc121\n",
      "data2/doc150\n",
      "data2/doc18\n",
      "data2/doc98\n",
      "data2/doc83\n",
      "data2/doc145\n",
      "data2/doc117\n",
      "data2/doc46\n",
      "data2/doc45\n",
      "data2/doc84\n",
      "data2/doc135\n",
      "data2/doc136\n",
      "data2/doc115\n",
      "data2/doc130\n",
      "data2/doc43\n",
      "data2/doc113\n",
      "data2/doc146\n",
      "data2/doc143\n",
      "data2/doc91\n",
      "data2/doc57\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 6.38 s, sys: 128 ms, total: 6.51 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "\n",
    "n_docs=5\n",
    "\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(doc_preprocessor, count=n_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Documents:', 151)\n",
      "('Sentences:', 1609)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disaster = candidate_subclass('Disaster', ['Name','Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import DateMatcher, LocationMatcher\n",
    "ngrams         = Ngrams(n_max=7)\n",
    "#person_matcher = PersonMatcher(longest_match_only=True)\n",
    "location_matcher = LocationMatcher(longest_match_only=True)\n",
    "date_matcher = DateMatcher(longest_match_only=True)\n",
    "#dict=['earthquake','flood','cyclone','fire']\n",
    "#dictionary_matcher=DictionaryMatch(d=dict)\n",
    "cand_extractor = CandidateExtractor(Disaster, [ngrams, ngrams], [date_matcher, location_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document\n",
    "#from util import number_of_people\n",
    "\n",
    "\n",
    "docs = session.query(Document)\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if i % 3 == 2:\n",
    "            dev_sents.add(s)\n",
    "        elif i % 3 == 1:\n",
    "            train_sents.add(s)\n",
    "        else:\n",
    "            train_sents.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 1078, 0)\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_sents),len(train_sents),len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 68)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 21)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 0)\n",
      "CPU times: user 13.6 s, sys: 908 ms, total: 14.5 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Disaster).filter(Disaster.split == i).count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "                   \n",
    "meteorological_disasters = { 'storm', 'bizzard', 'tornado', 'hurricane', 'cyclone', 'avalanches', 'heatwave','coldwave' 'drought', 'hailstorm'}\n",
    "hydrological_disasters = { 'flood' , 'tsunami', 'limnic eruption' , 'famine' , 'forest fire' }\n",
    "\n",
    "geological_disasters = { 'earthquake', 'volcano' , 'rock fall'}\n",
    "\n",
    "                   \n",
    "biological_disasters = { 'epidemic', 'pandemic' , 'influenza'}\n",
    "\n",
    "manmade_disasters = { 'blast', 'bomb explosion', 'bomb blast', 'bomb', 'bombings', 'surgical strike', 'shooting', 'firing', 'gun fire' , 'riots' , 'armed conflict'}\n",
    "\n",
    "def LF_mdisaster(c):\n",
    "     return 1 if len(meteorological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_hdisaster(c):\n",
    "    return 1 if len(hydrological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_gdisaster(c):\n",
    "    return 1 if len(geological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_bdisaster(c):\n",
    "    return 1 if len(biological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_mandisaster(c):\n",
    "    return 1 if len(manmade_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "def LF_tdisaster(c):\n",
    "      return 1 if 'train’' in get_between_tokens(c) and 'collided’' in get_right_tokens(c) else 0\n",
    "def LF_killed(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+killed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I)  else 0\n",
    "\n",
    "def LF_injured(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+injured+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I)  else 0\n",
    "\n",
    "def LF_dead(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+dead+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_damage(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+heavy+\\s+damage+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_conflict(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+conflict+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "trigger1 = ['killed', 'kills', 'killing']\n",
    "\n",
    "def LF_kill(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger1) + '.\\w', 1)\n",
    "trigger2 = ['violence', 'violent', 'rioting']\n",
    "def LF_violence(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger2) + '.\\w', 1)\n",
    "trigger3 = ['crashed’,’collided’,’hit’']\n",
    "\n",
    "def LF_crash(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger3) + '.\\w', 1)\n",
    "\n",
    "trigger4 = ['surgical strike', 'strike', 'struck', 'hit the target']\n",
    "\n",
    "def LF_strike(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) + '.\\w', 1)\n",
    "\n",
    "trigger5 = ['cold', 'heat']\n",
    "\n",
    "def LF_wave(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) +\"wave\"+ '.\\w', 1)\n",
    "def LF_cold(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+cold+arctic +air+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "trigger6 = ['flood' ,'floods' , 'flooding', 'flooded']\n",
    "def LF_flood(c):\n",
    "     return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) + '.\\w', 1)\n",
    "\n",
    "trigger7 = ['eruption' ,'erupting' , 'erupted',  'erupt']\n",
    "\n",
    "def LF_eruption(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger7) + '.\\w', 1)\n",
    "\n",
    "trigger8 = ['fell off' ,'slide', 'fall']\n",
    "\n",
    "#def LF_rock(c):\n",
    "    #return rule_regex_search_btw_AB(c, '.\\w' + rock + ltp(trigger8) + '.\\w', 1)\n",
    "\n",
    "trigger9 = ['cholera' ,'ebola', 'dengue']\n",
    "\n",
    "def LF_epidemic(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger9) + '.\\w', 1)\n",
    "\n",
    "\n",
    "def LF_tsunami(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+tsunami+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_confront(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+armed+confrontation+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_rammed(c):\n",
    "    return 1 if re.search (r'{{A}}+LF_rammed\\w+\\s+rammed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_smashed(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+smashed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_exploded(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+exploded+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_shipwrecked(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+shipwrecked+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_nuclearmeltdown(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+nuclear meltdown.+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_tornado(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+tornado(es)+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_limniceruption(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+limnic eruption+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_wildfire(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+wildfire(es)+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "     LF_mdisaster,  LF_gdisaster,  LF_hdisaster,  LF_bdisaster,  LF_mandisaster, LF_tdisaster, LF_wildfire,LF_limniceruption, LF_tornado\n",
    ",LF_nuclearmeltdown, LF_shipwrecked  ,LF_exploded, LF_smashed, LF_rammed,  LF_confront,LF_tsunami ,LF_epidemic,LF_eruption,LF_flood,\n",
    "LF_wave,LF_strike, LF_crash, LF_violence, LF_kill, LF_conflict, LF_damage, LF_dead, LF_injured, LF_kill ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open(\"output1.txt\",'w')\n",
    "f.seek(0)\n",
    "f.write(str(L_train))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disaster(Span(\"5100\", sentence=1563, chars=[172,175], words=[31,31]), Span(\"the Lower 9th Ward\", sentence=1563, chars=[207,224], words=[38,41]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.get_candidate(session, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12413886,  0.13380363,  0.10580794,  0.07506928,  0.08489036,\n",
       "        0.06854687,  0.09529703,  0.0820241 ,  0.08241606,  0.04963128,\n",
       "        0.08174002,  0.07691405,  0.06367795,  0.08603358,  0.04208157,\n",
       "        0.0800324 ,  0.08263257,  0.09499151,  0.08173692,  0.07733761,\n",
       "        0.07974053,  0.07920366,  0.07611276,  0.09176501,  0.08364014,\n",
       "        0.06999395,  0.06070118,  0.0937695 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555042</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.558449</td>\n",
       "      <td>0.367917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.567604</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.571344</td>\n",
       "      <td>0.384278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.547968</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.547190</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.541962</td>\n",
       "      <td>0.365922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531814</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>0.353551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.532389</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.355746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.541295</td>\n",
       "      <td>0.6623</td>\n",
       "      <td>0.546993</td>\n",
       "      <td>0.361133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.534496</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.535207</td>\n",
       "      <td>0.353352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.547238</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.543340</td>\n",
       "      <td>0.358939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.522184</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.520311</td>\n",
       "      <td>0.347566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.530825</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.531751</td>\n",
       "      <td>0.370910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.549532</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.552019</td>\n",
       "      <td>0.373703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.535575</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.534731</td>\n",
       "      <td>0.356345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.553654</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.558893</td>\n",
       "      <td>0.378691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.526932</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.527169</td>\n",
       "      <td>0.350359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.538553</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.544031</td>\n",
       "      <td>0.367318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.542224</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.545482</td>\n",
       "      <td>0.363727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.552511</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.553701</td>\n",
       "      <td>0.364126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.545537</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.549062</td>\n",
       "      <td>0.356145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.539671</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.541008</td>\n",
       "      <td>0.361931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.532321</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.533194</td>\n",
       "      <td>0.357342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.535058</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>0.531022</td>\n",
       "      <td>0.363727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.545876</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.555454</td>\n",
       "      <td>0.363727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.549247</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.549791</td>\n",
       "      <td>0.367917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.548426</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>0.548773</td>\n",
       "      <td>0.365922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.536640</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.360734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.522564</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.518960</td>\n",
       "      <td>0.330407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.551829</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.549586</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Coverage  Precision    Recall\n",
       "0   0.555042    0.6713   0.558449  0.367917\n",
       "1   0.567604    0.6723   0.571344  0.384278\n",
       "2   0.547968    0.6619   0.547009  0.357542\n",
       "3   0.547190    0.6601   0.541962  0.365922\n",
       "4   0.531814    0.6758   0.533896  0.353551\n",
       "5   0.532389    0.6638   0.531446  0.355746\n",
       "6   0.541295    0.6623   0.546993  0.361133\n",
       "7   0.534496    0.6653   0.535207  0.353352\n",
       "8   0.547238    0.6626   0.543340  0.358939\n",
       "9   0.522184    0.6649   0.520311  0.347566\n",
       "10  0.530825    0.6699   0.531751  0.370910\n",
       "11  0.549532    0.6733   0.552019  0.373703\n",
       "12  0.535575    0.6690   0.534731  0.356345\n",
       "13  0.553654    0.6719   0.558893  0.378691\n",
       "14  0.526932    0.6665   0.527169  0.350359\n",
       "15  0.538553    0.6718   0.544031  0.367318\n",
       "16  0.542224    0.6726   0.545482  0.363727\n",
       "17  0.552511    0.6751   0.553701  0.364126\n",
       "18  0.545537    0.6654   0.549062  0.356145\n",
       "19  0.539671    0.6743   0.541008  0.361931\n",
       "20  0.532321    0.6714   0.533194  0.357342\n",
       "21  0.535058    0.6689   0.531022  0.363727\n",
       "22  0.545876    0.6692   0.555454  0.363727\n",
       "23  0.549247    0.6640   0.549791  0.367917\n",
       "24  0.548426    0.6701   0.548773  0.365922\n",
       "25  0.536640    0.6714   0.535228  0.360734\n",
       "26  0.522564    0.6537   0.518960  0.330407\n",
       "27  0.551829    0.6589   0.549586  0.357143"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open(\"train_marginals1.txt\",'w')\n",
    "f.write(str(train_marginals))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_dev = labeler.apply(split=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open(\"L_dev.txt1\",'w')\n",
    "f.write(str(L_dev))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disaster(Span(\"Sunday\", sentence=1706, chars=[3,8], words=[1,1]), Span(\"Southwest\", sentence=1706, chars=[14,22], words=[3,3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.get_candidate(session, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disaster(Span(\"20\", sentence=858, chars=[131,132], words=[28,28]), Span(\"Ramanathapuram\", sentence=858, chars=[51,64], words=[11,11]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.get_candidate(session, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disaster(Span(\"20\", sentence=858, chars=[92,93], words=[18,18]), Span(\"Ramanathapuram\", sentence=858, chars=[51,64], words=[11,11]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.get_candidate(session, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open(\"L_gold.txt1\",'w')\n",
    "f.write(str(L_gold_dev))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(marginals):\n",
    "    predicted_labels=[]\n",
    "    for i in marginals:\n",
    "        if(i<=0.5): \n",
    "            predicted_labels.append(-1)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    return predicted_labels\n",
    "x=predict_labels(train_marginals)\n",
    "f=open(\"L_pred.txt1\",'w')\n",
    "f.write(str(x))\n",
    "#f.write(str(len(x))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11029411764705882, 0.5, 0.18072289156626503, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "x=np.array(x)\n",
    "list=np.ones((68,), dtype=int)\n",
    "precision_recall_fscore_support(x, list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
