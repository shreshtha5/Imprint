{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.parser import TextDocPreprocessor\n",
    "\n",
    "# doc_preprocessor = TextDocPreprocessor('disasterData/doc1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TextDocPreprocessor2\n",
    "doc_preprocessor = TextDocPreprocessor2('data2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========                                ] 20%data2/doc7\n",
      "[========                                ] 20%data2/doc40\n",
      "[================                        ] 40%data2/doc116\n",
      "[========================                ] 60%data2/doc137\n",
      "[================================        ] 80%data2/doc19\n",
      "[========================================] 100%data2/doc20\n",
      "[================================================] 120%data2/doc71\n",
      "data2/doc14\n",
      "data2/doc95\n",
      "data2/doc59\n",
      "data2/doc58\n",
      "data2/doc3\n",
      "data2/doc141\n",
      "data2/doc56\n",
      "data2/doc104\n",
      "data2/doc13\n",
      "data2/doc72\n",
      "data2/doc129\n",
      "data2/doc9\n",
      "data2/doc78\n",
      "data2/doc106\n",
      "data2/doc93\n",
      "data2/doc131\n",
      "data2/doc51\n",
      "data2/doc8\n",
      "data2/doc94\n",
      "data2/doc47\n",
      "data2/doc23\n",
      "data2/doc144\n",
      "data2/doc67\n",
      "data2/doc74\n",
      "data2/doc44\n",
      "data2/doc70\n",
      "data2/doc64\n",
      "data2/doc133\n",
      "data2/doc124\n",
      "data2/doc118\n",
      "data2/doc111\n",
      "data2/doc100\n",
      "data2/doc82\n",
      "data2/doc114\n",
      "data2/doc123\n",
      "data2/doc69\n",
      "data2/doc4\n",
      "data2/doc103\n",
      "data2/doc12\n",
      "data2/doc80\n",
      "data2/doc149\n",
      "data2/doc21\n",
      "data2/doc61\n",
      "data2/doc79\n",
      "data2/doc24\n",
      "data2/doc34\n",
      "data2/doc36\n",
      "data2/doc85\n",
      "data2/doc54\n",
      "data2/doc128\n",
      "data2/doc132\n",
      "data2/doc105\n",
      "data2/doc53\n",
      "data2/doc92\n",
      "data2/doc49\n",
      "data2/doc112\n",
      "data2/doc102\n",
      "data2/doc109\n",
      "data2/doc28\n",
      "data2/doc142\n",
      "data2/doc76\n",
      "data2/doc87\n",
      "data2/doc77\n",
      "data2/doc17\n",
      "data2/doc2\n",
      "data2/doc88\n",
      "data2/doc33\n",
      "data2/doc25\n",
      "data2/doc32\n",
      "data2/doc90\n",
      "data2/doc110\n",
      "data2/doc5\n",
      "data2/doc99\n",
      "data2/doc31\n",
      "data2/doc122\n",
      "data2/doc29\n",
      "data2/doc101\n",
      "data2/doc63\n",
      "data2/doc48\n",
      "data2/doc10\n",
      "data2/doc148\n",
      "data2/doc138\n",
      "data2/doc120\n",
      "data2/doc35\n",
      "data2/doc75\n",
      "data2/doc108\n",
      "data2/doc62\n",
      "data2/doc11\n",
      "data2/doc16\n",
      "data2/doc73\n",
      "data2/doc15\n",
      "data2/doc134\n",
      "data2/doc52\n",
      "data2/doc97\n",
      "data2/doc89\n",
      "data2/doc26\n",
      "data2/doc60\n",
      "data2/doc140\n",
      "data2/doc119\n",
      "data2/doc6\n",
      "data2/doc42\n",
      "data2/doc38\n",
      "data2/doc50\n",
      "data2/doc30\n",
      "data2/doc81\n",
      "data2/doc22\n",
      "data2/doc1\n",
      "data2/doc39\n",
      "data2/doc127\n",
      "data2/doc151\n",
      "data2/doc65\n",
      "data2/doc68\n",
      "data2/doc126\n",
      "data2/doc139\n",
      "data2/doc66\n",
      "data2/doc55\n",
      "data2/doc147\n",
      "data2/doc96\n",
      "data2/doc86\n",
      "data2/doc37\n",
      "data2/doc41\n",
      "data2/doc27\n",
      "data2/doc107\n",
      "data2/doc125\n",
      "data2/doc121\n",
      "data2/doc150\n",
      "data2/doc18\n",
      "data2/doc98\n",
      "data2/doc83\n",
      "data2/doc145\n",
      "data2/doc117\n",
      "data2/doc46\n",
      "data2/doc45\n",
      "data2/doc84\n",
      "data2/doc135\n",
      "data2/doc136\n",
      "data2/doc115\n",
      "data2/doc130\n",
      "data2/doc43\n",
      "data2/doc113\n",
      "data2/doc146\n",
      "data2/doc143\n",
      "data2/doc91\n",
      "data2/doc57\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 5.89 s, sys: 184 ms, total: 6.08 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "\n",
    "n_docs=5\n",
    "\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(doc_preprocessor, count=n_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Documents:', 151)\n",
      "('Sentences:', 1609)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disaster = candidate_subclass('Disaster', ['Name','Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import DateMatcher, LocationMatcher\n",
    "ngrams         = Ngrams(n_max=7)\n",
    "#person_matcher = PersonMatcher(longest_match_only=True)\n",
    "location_matcher = LocationMatcher(longest_match_only=True)\n",
    "date_matcher=DateMatcher(longest_match_only=True)\n",
    "#dict=['earthquake','flood','cyclone','fire']\n",
    "#dictionary_matcher=DictionaryMatch(d=dict)\n",
    "cand_extractor = CandidateExtractor(Disaster, [ngrams, ngrams], [date_matcher, location_matcher])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Document\n",
    "#from util import number_of_people\n",
    "\n",
    "\n",
    "docs = session.query(Document)\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if i % 3 == 2:\n",
    "            dev_sents.add(s)\n",
    "        elif i % 3 == 1:\n",
    "            dev_sents.add(s)\n",
    "        else:\n",
    "            dev_sents.add(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1609, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_sents),len(train_sents),len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 0)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 89)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 0)\n",
      "CPU times: user 12.5 s, sys: 432 ms, total: 12.9 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Disaster).filter(Disaster.split == i).count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "import csv\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "print(1)\n",
    "\n",
    "\n",
    "#tree = ET.parse(\"../../rnd/DisasterAnnotatedDocs-English-AUKBC/doc1_tagged.xml\")\n",
    "#tree = ET.parse(\"../../rnd/gold\")\n",
    "#root = tree.getroot()\n",
    "'''i=1\n",
    "def input_file():\n",
    "    global i\n",
    "    tree = ET.parse(\"../../rnd/gold/doc\"+str(i)+\"_tagged.xml\")\n",
    "    i=i+1\n",
    "    print(tree)\n",
    "    return(tree)'''    \n",
    "    \n",
    "#parent_map = dict((c, p) for p in tree.getiterator() for c in p)\n",
    "with open('gold_labels.tsv', 'w') as tsvfile:\n",
    "        writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "        writer.writerow([\"Name\", \"Location\", \"label\"])\n",
    "        for i in range(1,152):\n",
    "            if i!=31:\n",
    "                    tree = ET.parse(\"../../rnd/gold/doc\"+str(i)+\"_tagged.xml\")\n",
    "                    root = tree.getroot()\n",
    "                    parent_map = dict((c, p) for p in tree.getiterator() for c in p)\n",
    "                    print(\"doc\"+str(i))\n",
    "            \n",
    "        #tree=input_file()\n",
    "\n",
    "                    for nateve in root.findall(\".//NATURAL_EVENT\"):\n",
    "    \n",
    "                            a=0\n",
    "                            b=0\n",
    "                            s=''\n",
    "                            r=''\n",
    "                            print nateve.attrib[\"ID\"],ET.tostring(nateve)\n",
    "                            place = \"\"\n",
    "                            time = \"\"\n",
    "                            eventid = \"\"\n",
    "                            links = root.findall(\".//LINK[@EVENT_ARG=\\\"{}\\\"]\".format(nateve.attrib[\"ID\"]))\n",
    "                            for link in links:\n",
    "\n",
    "                                x = parent_map[link]\n",
    "                                if(x.tag==\"PLACE-ARG\"):\n",
    "                                    print x.tag\n",
    "                                    for c in x:\n",
    "                                        if(c.tag == \"W\"):\n",
    "                                            a=1\n",
    "                                            print c.text\n",
    "                                            s=c.text+s\n",
    "                            links = root.findall(\".//LINK[@EVENT_ARG=\\\"{}\\\"]\".format(nateve.attrib[\"ID\"]))\n",
    "                            for link in links:\n",
    "\n",
    "                                x = parent_map[link]\n",
    "                                if(x.tag==\"TIME-ARG\"):\n",
    "                                    print x.tag\n",
    "                                    for c in x:\n",
    "                                        if(c.tag == \"W\"):\n",
    "                                            b=1\n",
    "                                            print c.text\n",
    "                                            r=c.text+r\n",
    "                                            \n",
    "                            if(a==1 and b==1):\n",
    "                                    writer.writerow([r,s,str(1)])\n",
    "                            elif(a==1 and b==0):\n",
    "                 #record_file.write(s+\"  \"+str(\"\")+\"  \"+str(-1)+\"\\n\")\n",
    "                                       writer.writerow([\"\",s,str(-1)])\n",
    "                            elif(a==0 and b==1):\n",
    "                 #record_file.write(str(\"\")+\"  \"+r+\"  \"+str(-1)+\"\\n\")\n",
    "                                        writer.writerow([r,\"\",str(-1)+\"\\n\"])\n",
    "                            else:\n",
    "                 #record_file.write(str(\"\")+\"  \"+str(\"\")+\"  \"+str(-1)+\"\\n\")'''\n",
    "                                       writer.writerow([\"\",\"\",str(-1)])\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    for nateve in root.findall(\".//MAN_MADE_EVENT\"):\n",
    "    \n",
    "                            a=0\n",
    "                            b=0\n",
    "                            s=''\n",
    "                            r=''\n",
    "                            print nateve.attrib[\"ID\"],ET.tostring(nateve)\n",
    "                            place = \"\"\n",
    "                            time = \"\"\n",
    "                            eventid = \"\"\n",
    "                            links = root.findall(\".//LINK[@EVENT_ARG=\\\"{}\\\"]\".format(nateve.attrib[\"ID\"]))\n",
    "                            for link in links:\n",
    "\n",
    "                                x = parent_map[link]\n",
    "                                if(x.tag==\"PLACE-ARG\"):\n",
    "                                    print x.tag\n",
    "                                    for c in x:\n",
    "                                        if(c.tag == \"W\"):\n",
    "                                            a=1\n",
    "                                            print c.text\n",
    "                                            s=c.text+s\n",
    "                            links = root.findall(\".//LINK[@EVENT_ARG=\\\"{}\\\"]\".format(nateve.attrib[\"ID\"]))\n",
    "                            for link in links:\n",
    "\n",
    "                                x = parent_map[link]\n",
    "                                if(x.tag==\"TIME-ARG\"):\n",
    "                                    print x.tag\n",
    "                                    for c in x:\n",
    "                                        if(c.tag == \"W\"):\n",
    "                                            b=1\n",
    "                                            print c.text\n",
    "                                            r=c.text+r\n",
    "\n",
    "\n",
    "                    #print(type(c.text))\n",
    "    \n",
    "                            if(a==1 and b==1):\n",
    "                                    writer.writerow([r,s,str(1)])\n",
    "                            elif(a==1 and b==0):\n",
    "                 #record_file.write(r+\"  \"+str(\"\")+\"  \"+str(-1)+\"\\n\")\n",
    "                                       writer.writerow([\"\",s,str(-1)])\n",
    "                            elif(a==0 and b==1):\n",
    "                 #record_file.write(str(\"\")+\"  \"+s+\"  \"+str(-1)+\"\\n\")\n",
    "                                        writer.writerow([r,\"\",str(-1)+\"\\n\"])\n",
    "                            else:\n",
    "                 #record_file.write(str(\"\")+\"  \"+str(\"\")+\"  \"+str(-1)+\"\\n\")'''\n",
    "                                       writer.writerow([\"\",\"\",str(-1)])\n",
    "\n",
    "\n",
    "    \n",
    "#     print(place.tag,place.text)\n",
    "#     for x in nateve:\n",
    "#         print x.tag,x.text\n",
    "# root.find(\".//entity[@id=\\\"{}\\\"]\".format(cand['entity1id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (util.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"util.py\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    query = session.query(StableLabel)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "from util import load_external_labels\n",
    "\n",
    "%time missed = load_external_labels(session, Disaster, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for c in session.query(Disaster).filter(Disaster.split == 0).all():\n",
    "    #print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d6b3e2941a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDisaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDisaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mLF_mdisaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlabeled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number labeled:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "labeled = []\n",
    "for c in session.query(Disaster).filter(Disaster.split == 0).all():\n",
    "    if LF_mdisaster(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = []\n",
    "for c in session.query(Disaster).filter(Disaster.split == 1).all():\n",
    "    if LF_mandisaster(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cf737bf65444ee9cef64377d081a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "SentenceNgramViewer(labeled, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "                   \n",
    "meteorological_disasters = { 'storm', 'bizzard', 'tornado', 'hurricane', 'cyclone', 'avalanches', 'heatwave','coldwave' 'drought', 'hailstorm'}\n",
    "hydrological_disasters = { 'flood' , 'tsunami', 'limnic eruption' , 'famine' , 'forest fire' }\n",
    "\n",
    "geological_disasters = { 'earthquake', 'volcano' , 'rock fall'}\n",
    "\n",
    "                   \n",
    "biological_disasters = { 'epidemic', 'pandemic' , 'influenza'}\n",
    "\n",
    "manmade_disasters = { 'blast', 'bomb explosion', 'bomb blast', 'bomb', 'bombings', 'surgical strike', 'shooting', 'firing', 'gun fire' , 'riots' , 'armed conflict'}\n",
    "\n",
    "def LF_mdisaster(c):\n",
    "     return 1 if len(meteorological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_hdisaster(c):\n",
    "    return 1 if len(hydrological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_gdisaster(c):\n",
    "    return 1 if len(geological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_bdisaster(c):\n",
    "    return 1 if len(biological_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_mandisaster(c):\n",
    "    return 1 if len(manmade_disasters.intersection(get_between_tokens(c))) > 0 else 0\n",
    "def LF_tdisaster(c):\n",
    "      return 1 if 'train’' in get_between_tokens(c) and 'collided’' in get_right_tokens(c) else 0\n",
    "def LF_killed(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+killed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I)  else 0\n",
    "\n",
    "def LF_injured(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+injured+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I)  else 0\n",
    "\n",
    "def LF_dead(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+dead+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_damage(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+heavy+\\s+damage+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_conflict(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+conflict+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "trigger1 = ['killed', 'kills', 'killing']\n",
    "\n",
    "def LF_kill(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger1) + '.\\w', 1)\n",
    "trigger2 = ['violence', 'violent', 'rioting']\n",
    "def LF_violence(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger2) + '.\\w', 1)\n",
    "trigger3 = ['crashed’,’collided’,’hit’']\n",
    "\n",
    "def LF_crash(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger3) + '.\\w', 1)\n",
    "\n",
    "trigger4 = ['surgical strike', 'strike', 'struck', 'hit the target']\n",
    "\n",
    "def LF_strike(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) + '.\\w', 1)\n",
    "\n",
    "trigger5 = ['cold', 'heat']\n",
    "\n",
    "def LF_wave(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) +\"wave\"+ '.\\w', 1)\n",
    "def LF_cold(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+cold+arctic +air+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "trigger6 = ['flood' ,'floods' , 'flooding', 'flooded']\n",
    "def LF_flood(c):\n",
    "     return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger4) + '.\\w', 1)\n",
    "\n",
    "trigger7 = ['eruption' ,'erupting' , 'erupted',  'erupt']\n",
    "\n",
    "def LF_eruption(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger7) + '.\\w', 1)\n",
    "\n",
    "trigger8 = ['fell off' ,'slide', 'fall']\n",
    "\n",
    "#def LF_rock(c):\n",
    "    #return rule_regex_search_btw_AB(c, '.\\w' + rock + ltp(trigger8) + '.\\w', 1)\n",
    "\n",
    "trigger9 = ['cholera' ,'ebola', 'dengue']\n",
    "\n",
    "def LF_epidemic(c):\n",
    "    return rule_regex_search_btw_AB(c, '.\\w' + ltp(trigger9) + '.\\w', 1)\n",
    "\n",
    "\n",
    "def LF_tsunami(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+tsunami+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_confront(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+armed+confrontation+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_rammed(c):\n",
    "    return 1 if re.search (r'{{A}}+LF_rammed\\w+\\s+rammed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_smashed(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+smashed+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_exploded(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+exploded+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_shipwrecked(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+shipwrecked+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_nuclearmeltdown(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+nuclear meltdown.+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_tornado(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+tornado(es)+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_limniceruption(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+limnic eruption+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0\n",
    "\n",
    "def LF_wildfire(c):\n",
    "    return 1 if re.search (r'{{A}}+\\w+\\s+wildfire(es)+\\s+\\w+{{B}}',  get_tagged_text(c), flags =re.I) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import snorkel.annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "     LF_mdisaster,  LF_gdisaster,  LF_hdisaster,  LF_bdisaster,  LF_mandisaster, LF_tdisaster, LF_wildfire,LF_limniceruption, LF_tornado\n",
    ",LF_nuclearmeltdown, LF_shipwrecked  ,LF_exploded, LF_smashed, LF_rammed,  LF_confront,LF_tsunami ,LF_epidemic,LF_eruption,LF_flood,\n",
    "LF_wave,LF_strike, LF_crash, LF_violence, LF_kill, LF_conflict, LF_damage, LF_dead, LF_injured, LF_kill ]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=1)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.13 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<0x0 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_mdisaster</th>\n",
       "      <td>0</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_gdisaster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_hdisaster</th>\n",
       "      <td>2</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_bdisaster</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_mandisaster</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tdisaster</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_wildfire</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_limniceruption</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tornado</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_nuclearmeltdown</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_shipwrecked</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_exploded</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_smashed</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_rammed</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_confront</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tsunami</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_epidemic</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_eruption</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_flood</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_wave</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_strike</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_crash</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_violence</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_kill</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_conflict</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_damage</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_dead</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_injured</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j  Coverage  Overlaps  Conflicts\n",
       "LF_mdisaster         0  0.067416  0.000000        0.0\n",
       "LF_gdisaster         1  0.101124  0.033708        0.0\n",
       "LF_hdisaster         2  0.056180  0.033708        0.0\n",
       "LF_bdisaster         3  0.000000  0.000000        0.0\n",
       "LF_mandisaster       4  0.000000  0.000000        0.0\n",
       "LF_tdisaster         5  0.000000  0.000000        0.0\n",
       "LF_wildfire          6  0.000000  0.000000        0.0\n",
       "LF_limniceruption    7  0.000000  0.000000        0.0\n",
       "LF_tornado           8  0.000000  0.000000        0.0\n",
       "LF_nuclearmeltdown   9  0.000000  0.000000        0.0\n",
       "LF_shipwrecked      10  0.000000  0.000000        0.0\n",
       "LF_exploded         11  0.000000  0.000000        0.0\n",
       "LF_smashed          12  0.000000  0.000000        0.0\n",
       "LF_rammed           13  0.000000  0.000000        0.0\n",
       "LF_confront         14  0.000000  0.000000        0.0\n",
       "LF_tsunami          15  0.000000  0.000000        0.0\n",
       "LF_epidemic         16  0.000000  0.000000        0.0\n",
       "LF_eruption         17  0.000000  0.000000        0.0\n",
       "LF_flood            18  0.000000  0.000000        0.0\n",
       "LF_wave             19  0.000000  0.000000        0.0\n",
       "LF_strike           20  0.000000  0.000000        0.0\n",
       "LF_crash            21  0.000000  0.000000        0.0\n",
       "LF_violence         22  0.000000  0.000000        0.0\n",
       "LF_kill             23  0.000000  0.000000        0.0\n",
       "LF_conflict         24  0.000000  0.000000        0.0\n",
       "LF_damage           25  0.000000  0.000000        0.0\n",
       "LF_dead             26  0.000000  0.000000        0.0\n",
       "LF_injured          27  0.000000  0.000000        0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-01547c031c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/shreshtha/2nd_sem/seminar/snorkel-master/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mget_candidate\u001b[0;34m(self, session, i)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m\"\"\"Return the Candidate object corresponding to row i\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_row_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "L_train.get_candidate(session, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelKey (LF_mdisaster)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.get_key(session, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1285002 ,  0.12176998,  0.11403378,  0.07474443,  0.09075024,\n",
       "        0.0767384 ,  0.07119023,  0.06212787,  0.06721162,  0.05644994,\n",
       "        0.08115259,  0.04437729,  0.07741764,  0.07553978,  0.05798367,\n",
       "        0.07684375,  0.04994734,  0.08945969,  0.06329529,  0.07153999,\n",
       "        0.07115216,  0.07100951,  0.06979111,  0.07470675,  0.09042339,\n",
       "        0.04918879,  0.07346887,  0.08018315])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566727</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.557744</td>\n",
       "      <td>0.377881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.567244</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.557480</td>\n",
       "      <td>0.377477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558161</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.550863</td>\n",
       "      <td>0.374444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533927</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.527594</td>\n",
       "      <td>0.355641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.543475</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.543844</td>\n",
       "      <td>0.372422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.542526</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.535671</td>\n",
       "      <td>0.358269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.548233</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.539870</td>\n",
       "      <td>0.369592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.529603</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.524576</td>\n",
       "      <td>0.356045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.537040</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.532004</td>\n",
       "      <td>0.361302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.531725</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.369187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.536906</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.530921</td>\n",
       "      <td>0.347149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.522980</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.511059</td>\n",
       "      <td>0.350384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.534081</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.530979</td>\n",
       "      <td>0.358674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.543455</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.531782</td>\n",
       "      <td>0.360291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.533496</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.531801</td>\n",
       "      <td>0.341488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.553536</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.546522</td>\n",
       "      <td>0.357461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.530714</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.525292</td>\n",
       "      <td>0.354832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.548999</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.547384</td>\n",
       "      <td>0.370198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.537195</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.530060</td>\n",
       "      <td>0.360089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.533787</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.527295</td>\n",
       "      <td>0.355439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.539336</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.533634</td>\n",
       "      <td>0.359280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.533403</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.527060</td>\n",
       "      <td>0.354428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.537871</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.535296</td>\n",
       "      <td>0.360291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.537587</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.531211</td>\n",
       "      <td>0.347554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.538682</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.536325</td>\n",
       "      <td>0.355237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.532217</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.520420</td>\n",
       "      <td>0.350384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.538922</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.538807</td>\n",
       "      <td>0.363526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.540484</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.526969</td>\n",
       "      <td>0.369389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  Coverage  Precision    Recall\n",
       "0   0.566727    0.6684   0.557744  0.377881\n",
       "1   0.567244    0.6759   0.557480  0.377477\n",
       "2   0.558161    0.6654   0.550863  0.374444\n",
       "3   0.533927    0.6735   0.527594  0.355641\n",
       "4   0.543475    0.6705   0.543844  0.372422\n",
       "5   0.542526    0.6737   0.535671  0.358269\n",
       "6   0.548233    0.6707   0.539870  0.369592\n",
       "7   0.529603    0.6773   0.524576  0.356045\n",
       "8   0.537040    0.6709   0.532004  0.361302\n",
       "9   0.531725    0.6714   0.532051  0.369187\n",
       "10  0.536906    0.6625   0.530921  0.347149\n",
       "11  0.522980    0.6658   0.511059  0.350384\n",
       "12  0.534081    0.6690   0.530979  0.358674\n",
       "13  0.543455    0.6685   0.531782  0.360291\n",
       "14  0.533496    0.6553   0.531801  0.341488\n",
       "15  0.553536    0.6603   0.546522  0.357461\n",
       "16  0.530714    0.6642   0.525292  0.354832\n",
       "17  0.548999    0.6694   0.547384  0.370198\n",
       "18  0.537195    0.6681   0.530060  0.360089\n",
       "19  0.533787    0.6615   0.527295  0.355439\n",
       "20  0.539336    0.6597   0.533634  0.359280\n",
       "21  0.533403    0.6736   0.527060  0.354428\n",
       "22  0.537871    0.6641   0.535296  0.360291\n",
       "23  0.537587    0.6598   0.531211  0.347554\n",
       "24  0.538682    0.6644   0.536325  0.355237\n",
       "25  0.532217    0.6627   0.520420  0.350384\n",
       "26  0.538922    0.6680   0.538807  0.363526\n",
       "27  0.540484    0.6694   0.526969  0.369389"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_labels(marginals):\n",
    "    predicted_labels=[]\n",
    "    for i in marginals:\n",
    "        if(i<0.5): \n",
    "            predicted_labels.append(-1)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    return predicted_labels\n",
    "x=predict_labels(train_marginals)\n",
    "print(type(x))\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-34666a0cb9e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "my_list=[]\n",
    "with open(\"/home/shreshtha/2nd_sem/seminar/snorkel-master/gold_labels.tsv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    my_list = [row[-1] for row in reader]\n",
    "list=np.array(my_list)\n",
    "list.append(1)\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "my_list=[]\n",
    "with open(\"/home/shreshtha/2nd_sem/seminar/snorkel-master/gold_labels.tsv\") as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    \n",
    "    my_list = [row[-1] for row in reader]\n",
    "\n",
    "for i in range(0,7):    \n",
    "    my_list.append('-1')\n",
    "print(len(my_list))\n",
    "list=np.array(my_list)\n",
    "print(list)\n",
    "#print(size(list))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [89, 779]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cded4fc2de6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/shreshtha/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreshtha/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreshtha/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [89, 779]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "x=np.array(x)\n",
    "precision_recall_fscore_support(x, list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_dev = labeler.apply(split=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sequence too large; cannot be greater than 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-50750e584756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_gold_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearned_lf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/shreshtha/2nd_sem/seminar/snorkel-master/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mlf_stats\u001b[0;34m(self, session, labels, est_accs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mcol_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Empirical Acc.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_tp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreshtha/2nd_sem/seminar/snorkel-master/snorkel/utils.pyc\u001b[0m in \u001b[0;36mmatrix_tp\u001b[0;34m(L, labels)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatrix_tp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     return np.ravel([\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m#numpy.dot(numpy.ones([97, 2]), numpy.ones([2, 1])).shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreshtha/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sequence too large; cannot be greater than 32"
     ]
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1fd269ca059c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_LF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_LF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLF_mdisaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "from snorkel.lf_helpers import test_LF\n",
    "tp, fp, tn, fn = test_LF(session, LF_mdisaster, split=1, annotator_name='gold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
